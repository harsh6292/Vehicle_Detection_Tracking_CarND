{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection And Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import cv2\n",
    "\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Debug variable to print output\n",
    "DBG = False#True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load car and non-car images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Cars in dataset: 8794\n",
      "Total number of Non-Cars in dataset: 8968\n"
     ]
    }
   ],
   "source": [
    "dataset_base_dir = 'dataset/'\n",
    "car_dataset = 'vehicles/'\n",
    "noncar_dataset = 'non-vehicles/'\n",
    "\n",
    "cars = []\n",
    "noncars = []\n",
    "\n",
    "# Get different folders inside the car dataset\n",
    "img_types = os.listdir(dataset_base_dir + car_dataset)\n",
    "\n",
    "for folder in img_types:\n",
    "    cars.extend(glob.glob(dataset_base_dir + car_dataset + folder + '/*'))\n",
    "\n",
    "# Get different folders inside the noncar dataset\n",
    "img_types = os.listdir(dataset_base_dir + noncar_dataset)\n",
    "\n",
    "for folder in img_types:\n",
    "    noncars.extend(glob.glob(dataset_base_dir + noncar_dataset + folder + '/*'))\n",
    "\n",
    "    \n",
    "print(\"Total number of Cars in dataset: {}\".format(len(cars)))\n",
    "print(\"Total number of Non-Cars in dataset: {}\".format(len(noncars)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Features from Image (HOG, Color Histogram and Bin Spatial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "# Color Histogram features\n",
    "###########################################\n",
    "\n",
    "# Assuming input channel is cv2 order (BGR)\n",
    "# Also check cv2 reads in png images in range (0, 256)\n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    \n",
    "    # Compute the histogram of the RGB channels separately\n",
    "    rhist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    ghist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    bhist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    \n",
    "    # Generating bin centers\n",
    "    bin_edges = rhist[1]\n",
    "    bin_centers = (bin_edges[1:] + bin_edges[0:len(bin_edges)-1])/2\n",
    "    \n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((rhist[0], ghist[0], bhist[0]))\n",
    "    \n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return rhist, ghist, bhist, bin_centers, hist_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "###########################################\n",
    "# Bin Spatial features\n",
    "###########################################\n",
    "\n",
    "# Remember to give src image in BGR format\n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    \n",
    "    # Resize the image to specified size\n",
    "    img_resized = cv2.resize(img, size)\n",
    "    \n",
    "    # Get features from image\n",
    "    bin_features = img_resized.ravel()\n",
    "    \n",
    "    return  bin_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "# HOG (Histogram of Oriented gradients) features\n",
    "###########################################\n",
    "\n",
    "def get_hog_features(one_channel_img, orient=9, pix_per_cell=8, cell_per_block=2, vis=False, feature_vect=True):\n",
    "    \n",
    "    # IF visualation is true, return the HOG image too\n",
    "    if vis == True:\n",
    "        hog_features, hog_img = hog(one_channel_img,\n",
    "                                orientations=orient,\n",
    "                                pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                cells_per_block=(cell_per_block, cell_per_block),\n",
    "                                visualise=vis,\n",
    "                                feature_vector=feature_vect)\n",
    "        \n",
    "        return hog_features, hog_img\n",
    "    else:\n",
    "        hog_features = hog(one_channel_img,\n",
    "                                orientations=orient,\n",
    "                                pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                cells_per_block=(cell_per_block, cell_per_block),\n",
    "                                visualise=vis,\n",
    "                                feature_vector=feature_vect)\n",
    "        return hog_features\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "# Get combined features (Bin Spatial, Histogram and HOG)\n",
    "########################################### \n",
    "\n",
    "def single_img_feature(img,\n",
    "                       cspace='RGB', \n",
    "                       spatial_size=(32, 32), \n",
    "                       hist_bins=32, hist_range=(0, 256),\n",
    "                       orient=9, pix_per_cell=8, cell_per_block=2,\n",
    "                       hog_channel=0,\n",
    "                       spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    \n",
    "    feature_image = np.copy(img) \n",
    "    single_img_feature = []\n",
    "    \n",
    "    if DBG == True:\n",
    "        print(feature_image.shape)\n",
    "    \n",
    "    # apply color conversion based on color space\n",
    "    if cspace == 'HSV':\n",
    "        feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    elif cspace == 'RGB':\n",
    "        feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    elif cspace == 'LUV':\n",
    "        feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2LUV)\n",
    "    elif cspace == 'HLS':\n",
    "        feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    elif cspace == 'YUV':\n",
    "        feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "    elif cspace == 'YCrCb':\n",
    "        feature_image = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)  \n",
    "    \n",
    "    #if DBG == True:\n",
    "    #    plt.imshow(feature_image, cmap='gray')\n",
    "    \n",
    "    if spatial_feat == True:\n",
    "        bin_spatial_features = bin_spatial(feature_image, size=spatial_size)    \n",
    "        single_img_feature.append(bin_spatial_features)\n",
    "        \n",
    "        if DBG == True:\n",
    "            print(\"Bin spatial features len: {}\".format(len(bin_spatial_features)))\n",
    "        \n",
    "        \n",
    "    if hist_feat == True:\n",
    "        rhist, ghist, bhist, bin_centers, color_hist_features = color_hist(feature_image, nbins=hist_bins, bins_range=hist_range)\n",
    "        single_img_feature.append(color_hist_features)\n",
    "        \n",
    "        if DBG == True:\n",
    "            print(\"Color histogram features len: {}\".format(len(color_hist_features)))\n",
    "        \n",
    "    if hog_feat == True:\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_feature = []\n",
    "        \n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                single_hog_channel_feat = get_hog_features(feature_image[:,:,channel],\n",
    "                                                           orient=orient, \n",
    "                                                           pix_per_cell=pix_per_cell, \n",
    "                                                           cell_per_block=cell_per_block, \n",
    "                                                           vis=False, \n",
    "                                                           feature_vect=True)\n",
    "                hog_feature.append(single_hog_channel_feat)\n",
    "        \n",
    "            hog_feature = np.ravel(hog_feature)\n",
    "        else:\n",
    "            hog_feature = get_hog_features(feature_image[:,:,hog_channel],\n",
    "                                           orient=orient, \n",
    "                                           pix_per_cell=pix_per_cell, \n",
    "                                           cell_per_block=cell_per_block, \n",
    "                                           vis=False, \n",
    "                                           feature_vect=True)\n",
    "            \n",
    "            #feat_hog, hog_image = get_hog_features(feature_image[:,:,hog_channel],\n",
    "            #                               orient=orient, \n",
    "            #                               pix_per_cell=pix_per_cell, \n",
    "            #                               cell_per_block=cell_per_block, \n",
    "            #                               vis=True, \n",
    "            #                               feature_vect=False)\n",
    "            #\n",
    "            #plt.imshow(hog_image, cmap='hot')\n",
    "            \n",
    "        # Add hog feature(s) to image features\n",
    "        single_img_feature.append(hog_feature)\n",
    "\n",
    "        if DBG == True:\n",
    "            print(\"HOG features len: {}\".format(len(hog_feature)))\n",
    "            \n",
    "    \n",
    "            \n",
    "    if DBG == True:\n",
    "        print('Single image feature len: {}'.format(len(single_img_feature)))\n",
    "    \n",
    "    \n",
    "    # Return concatenated features for a single image\n",
    "    features_concat = np.concatenate(single_img_feature, axis=0)\n",
    "    \n",
    "    if DBG == True:\n",
    "        print('Concatenated feature len: {}'.format(len(features_concat)))\n",
    "    \n",
    "    return features_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get features from a list of images\n",
    "def extract_features(list_of_imgs, \n",
    "                     cspace='RGB', \n",
    "                     spatial_size=(32, 32), \n",
    "                     hist_bins=32, hist_range=(0, 256),\n",
    "                     orient=9, pix_per_cell=8, cell_per_block=2,\n",
    "                     hog_channel=0,\n",
    "                     spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    \n",
    "    # Store all features for all images\n",
    "    total_features = []\n",
    "    \n",
    "    for img_path in list_of_imgs:\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        single_img_features = single_img_feature(img,\n",
    "                                                 cspace=cspace, \n",
    "                                                 spatial_size=spatial_size, \n",
    "                                                 hist_bins=hist_bins, \n",
    "                                                 hist_range=hist_range,\n",
    "                                                 orient=orient, \n",
    "                                                 pix_per_cell=pix_per_cell, \n",
    "                                                 cell_per_block=cell_per_block,\n",
    "                                                 hog_channel=hog_channel,\n",
    "                                                 spatial_feat=spatial_feat, \n",
    "                                                 hist_feat=hist_feat, \n",
    "                                                 hog_feat=hog_feat)\n",
    "\n",
    "        # Concatenate this image features (bin spatial, hist, hog) as one and append with other img feat list\n",
    "        total_features.append(single_img_features)\n",
    "        \n",
    "    return total_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Sliding Window Bounding Box in an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sliding_window_boxes(img, \n",
    "                   x_start_stop=[None, None], \n",
    "                   y_start_stop=[None, None],\n",
    "                   xy_window_size=(64, 64),\n",
    "                   xy_overlap_size=(0.5, 0.5)):\n",
    "    \n",
    "    # If x and/or y start/stop positions are not defined, set it to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    \n",
    "    # Calculate the image span to be searched\n",
    "    x_span = (x_start_stop[1] - x_start_stop[0])\n",
    "    y_span = (y_start_stop[1] - y_start_stop[0])\n",
    "    \n",
    "    # Calculate the number of pixels per window\n",
    "    nx_pix_per_step = np.int(xy_window_size[0] * (1 - xy_overlap_size[0]))\n",
    "    ny_pix_per_step = np.int(xy_window_size[1] * (1 - xy_overlap_size[1]))\n",
    "    \n",
    "    #Calculate the number of windows in x/y direction\n",
    "    nx_buffer = np.int(xy_window_size[0] * xy_overlap_size[0])\n",
    "    ny_buffer = np.int(xy_window_size[1] * xy_overlap_size[1])\n",
    "    \n",
    "    nx_windows = np.int( (x_span - nx_buffer) / nx_pix_per_step)\n",
    "    ny_windows = np.int( (y_span - ny_buffer) / ny_pix_per_step)\n",
    "    \n",
    "    \n",
    "    # Store window size in a list\n",
    "    window_list = []\n",
    "    \n",
    "    # Go through each window in x and y to calculate window position\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            \n",
    "            # Get window start position\n",
    "            start_x = ( (xs * nx_pix_per_step) + x_start_stop[0])\n",
    "            start_y = ( (ys * ny_pix_per_step) + y_start_stop[0])\n",
    "            \n",
    "            # Get the window end position\n",
    "            end_x = start_x + xy_window_size[0]\n",
    "            end_y = start_y + xy_window_size[1]\n",
    "            \n",
    "            # Append window position to list\n",
    "            window_list.append( ( (start_x, start_y), (end_x, end_y) ) )\n",
    "    \n",
    "    # Return the list of windows\n",
    "    return window_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw bounding box on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_boxes(img, bounding_boxes, color=(0, 0, 255), thick=6):\n",
    "    \n",
    "    img_copy = np.copy(img)\n",
    "    \n",
    "    # Go through all the bounding boxes and draw a rectangle\n",
    "    for box in bounding_boxes:\n",
    "        cv2.rectangle(img_copy, box[0], box[1], color, thick)\n",
    "\n",
    "    # Return image with boxes drawn\n",
    "    return img_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search and Classify Cars in Sliding Window Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_windows_and_classify(img,\n",
    "                                window_list,\n",
    "                                classifier,\n",
    "                                scaler,\n",
    "                                cspace='RGB', \n",
    "                                spatial_size=(32, 32), \n",
    "                                hist_bins=32, hist_range=(0, 256),\n",
    "                                orient=9, pix_per_cell=8, cell_per_block=2,\n",
    "                                hog_channel=0,\n",
    "                                spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    \n",
    "    #Store list of windows where car is detected\n",
    "    detected_car_windows = []\n",
    "    \n",
    "    # Go through all windows and apply classifier to detect if car is detected.\n",
    "    for window in window_list:\n",
    "        \n",
    "        #Extract the window size image from whole image and resize it to dataset image size\n",
    "        test_img = cv2.resize(img[window[0][1]:windpw[1][1], window[0][0]:window[1][0]], (64, 64))\n",
    "        \n",
    "        #Extract features from this test image\n",
    "        features = single_img_feature(img,\n",
    "                                     cspace=cspace, \n",
    "                                     spatial_size=spatial_size, \n",
    "                                     hist_bins=hist_bins, \n",
    "                                     hist_range=hist_range,\n",
    "                                     orient=orient, \n",
    "                                     pix_per_cell=pix_per_cell, \n",
    "                                     cell_per_block=cell_per_block,\n",
    "                                     hog_channel=hog_channel,\n",
    "                                     spatial_feat=spatial_feat, \n",
    "                                     hist_feat=hist_feat, \n",
    "                                     hog_feat=hog_feat)\n",
    "        \n",
    "        #Scale and normalize the features\n",
    "        scaled_features = scaler.transform(np.array(features).reshape(1, -1))\n",
    "        \n",
    "        #Make a prediction about this window image\n",
    "        predict = clf.predict(scaled_features)\n",
    "        \n",
    "        #If predicted to be a car, save it to car list\n",
    "        if predict == 1:\n",
    "            detected_car_windows.append(window)\n",
    "    \n",
    "    \n",
    "    # Return the list of windows in which car is detected\n",
    "    return detected_car_windows\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test feature extraction on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of car features: 4884\n",
      "Length of non-car features: 4884\n"
     ]
    }
   ],
   "source": [
    "car_index = np.random.randint(0, len(cars))\n",
    "not_car_index = np.random.randint(0, len(noncars))\n",
    "\n",
    "car_img = cv2.imread(cars[car_index])\n",
    "#car_img = cv2.imread('dataset/vehicles/KITTI_extracted/437.png')\n",
    "not_car_img = cv2.imread(noncars[not_car_index])\n",
    "\n",
    "\n",
    "#Define features values\n",
    "color_space = 'RGB'\n",
    "\n",
    "# Bin spatial feature - size to reduce image to\n",
    "spatial_size = (32, 32)\n",
    "\n",
    "# Color Histogram feature - No of histogram bins\n",
    "hist_bins = 16\n",
    "# Color Histogram feature - Histogram color range\n",
    "hist_range=(0, 256)\n",
    "\n",
    "# HOG feature - orientations\n",
    "orient = 9\n",
    "# HOG feature - No of pixels per cell\n",
    "pix_per_cell = 8\n",
    "# HOG feature - No of cells per block\n",
    "cell_per_block = 2\n",
    "# HOG feature - Channel to extract hog feature\n",
    "hog_channel = 0\n",
    "\n",
    "#Spatial features on or off\n",
    "spatial_feat = True\n",
    "#Histogram features on or off\n",
    "hist_feat = True \n",
    "#HOG features on or off\n",
    "hog_feat = True\n",
    "\n",
    "#Define Min and Max Y position to extract features in image\n",
    "y_start_stop = [450, 710]\n",
    "\n",
    "\n",
    "car_features = single_img_feature(car_img, cspace=color_space,  spatial_size=spatial_size, \n",
    "                       hist_bins=hist_bins, hist_range=hist_range,\n",
    "                       orient=orient, pix_per_cell=pix_per_cell, \n",
    "                       cell_per_block=cell_per_block, hog_channel=hog_channel,\n",
    "                       spatial_feat=spatial_feat, hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "\n",
    "\n",
    "not_car_features = single_img_feature(not_car_img, cspace=color_space,  spatial_size=spatial_size, \n",
    "                       hist_bins=hist_bins, hist_range=hist_range,\n",
    "                       orient=orient, pix_per_cell=pix_per_cell, \n",
    "                       cell_per_block=cell_per_block, hog_channel=hog_channel,\n",
    "                       spatial_feat=spatial_feat, hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "\n",
    "print(\"Length of car features: {}\".format(len(car_features)))\n",
    "print(\"Length of non-car features: {}\".format(len(not_car_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to compute features: 92.29773998260498\n",
      "Length of car features: 8794\n",
      "Length of non-car features: 8968\n"
     ]
    }
   ],
   "source": [
    "# Test feature extraction on list of images\n",
    "# cars = list of car images\n",
    "# noncars = list of non-car images\n",
    "\n",
    "\n",
    "#Define features values\n",
    "color_space = 'RGB'\n",
    "\n",
    "# Bin spatial feature - size to reduce image to\n",
    "spatial_size = (32, 32)\n",
    "\n",
    "# Color Histogram feature - No of histogram bins\n",
    "hist_bins = 16\n",
    "# Color Histogram feature - Histogram color range\n",
    "hist_range=(0, 256)\n",
    "\n",
    "# HOG feature - orientations\n",
    "orient = 9\n",
    "# HOG feature - No of pixels per cell\n",
    "pix_per_cell = 8\n",
    "# HOG feature - No of cells per block\n",
    "cell_per_block = 2\n",
    "# HOG feature - Channel to extract hog feature\n",
    "hog_channel = 'ALL'\n",
    "\n",
    "#Spatial features on or off\n",
    "spatial_feat = True\n",
    "#Histogram features on or off\n",
    "hist_feat = True \n",
    "#HOG features on or off\n",
    "hog_feat = True\n",
    "\n",
    "#Define Min and Max Y position to extract features in image\n",
    "y_start_stop = [450, 710]\n",
    "\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "car_features = extract_features(cars, cspace=color_space,  spatial_size=spatial_size, \n",
    "                       hist_bins=hist_bins, hist_range=hist_range,\n",
    "                       orient=orient, pix_per_cell=pix_per_cell, \n",
    "                       cell_per_block=cell_per_block, hog_channel=hog_channel,\n",
    "                       spatial_feat=spatial_feat, hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "\n",
    "\n",
    "not_car_features = extract_features(noncars, cspace=color_space,  spatial_size=spatial_size, \n",
    "                       hist_bins=hist_bins, hist_range=hist_range,\n",
    "                       orient=orient, pix_per_cell=pix_per_cell, \n",
    "                       cell_per_block=cell_per_block, hog_channel=hog_channel,\n",
    "                       spatial_feat=spatial_feat, hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "\n",
    "t_end = time.time()\n",
    "\n",
    "print('Total time to compute features: {} seconds'.format(t_end-t_start))\n",
    "print(\"Length of car features: {}\".format(len(car_features)))\n",
    "print(\"Length of non-car features: {}\".format(len(not_car_features)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector length: 8412\n"
     ]
    }
   ],
   "source": [
    "#Apply scalar transform to features to normalize them\n",
    "\n",
    "#Stack cars and noncars feature vectors to create one single feature for classification\n",
    "X = np.vstack((car_features, not_car_features)).astype(np.float64)\n",
    "\n",
    "#Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "\n",
    "#Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "\n",
    "#Define the labels vector\n",
    "y_labels = np.hstack( (np.ones(len(car_features)), np.zeros(len(not_car_features))) )\n",
    "\n",
    "\n",
    "# Now Split the data into training and testing set\n",
    "test_size = 0.2\n",
    "rand_state = np.random.randint(0, 100)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y_labels, test_size=test_size, random_state=rand_state)\n",
    "\n",
    "print('Feature vector length:', len(X_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a classifier on vehicle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Using: {} orientations, {} pixels per cell and {} cells per block.'.format(orient, pix_per_cell, cell_per_block)\n",
    "\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "\n",
    "t_start = time.time()\n",
    "\n",
    "#Fit the training data in SVM\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "t_end = time.time()\n",
    "\n",
    "print('SVM took {} seconds to train.'.format(round(t_end - t_start, 2)))\n",
    "\n",
    "#Calculate the accuracy of trained SVM with test samples\n",
    "print('Test Accuracy of SVC: {}', round(svc.score(X_test, y_test), 4))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "test_images_path = 'test_images/'\n",
    "test_images = glob.glob('test_images/test*.jpg')\n",
    "\n",
    "test_img = cv2.imread('test_images/test1.jpg')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot3d(pixels, colors_rgb,\n",
    "        axis_labels=list(\"RGB\"), axis_limits=((0, 255), (0, 255), (0, 255))):\n",
    "    \"\"\"Plot pixels in 3D.\"\"\"\n",
    "\n",
    "    # Create figure and 3D axes\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = Axes3D(fig)\n",
    "\n",
    "    # Set axis limits\n",
    "    ax.set_xlim(*axis_limits[0])\n",
    "    ax.set_ylim(*axis_limits[1])\n",
    "    ax.set_zlim(*axis_limits[2])\n",
    "\n",
    "    # Set axis labels and sizes\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14, pad=8)\n",
    "    ax.set_xlabel(axis_labels[0], fontsize=16, labelpad=16)\n",
    "    ax.set_ylabel(axis_labels[1], fontsize=16, labelpad=16)\n",
    "    ax.set_zlabel(axis_labels[2], fontsize=16, labelpad=16)\n",
    "\n",
    "    # Plot pixel values with colors given in colors_rgb\n",
    "    ax.scatter(\n",
    "        pixels[:, :, 0].ravel(),\n",
    "        pixels[:, :, 1].ravel(),\n",
    "        pixels[:, :, 2].ravel(),\n",
    "        c=colors_rgb.reshape((-1, 3)), edgecolors='none')\n",
    "\n",
    "    return ax  # return Axes3D object for further manipulation\n",
    "\n",
    "\n",
    "# Read a color image\n",
    "img = cv2.imread('test_images/test1.jpg')\n",
    "\n",
    "# Select a small fraction of pixels to plot by subsampling it\n",
    "scale = max(img.shape[0], img.shape[1], 64) / 64  # at most 64 rows and columns\n",
    "img_small = cv2.resize(img, (np.int(img.shape[1] / scale), np.int(img.shape[0] / scale)), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "# Convert subsampled image to desired color space(s)\n",
    "img_small_RGB = cv2.cvtColor(img_small, cv2.COLOR_BGR2RGB)  # OpenCV uses BGR, matplotlib likes RGB\n",
    "img_small_HSV = cv2.cvtColor(img_small, cv2.COLOR_BGR2HSV)\n",
    "img_small_rgb = img_small_RGB / 255.  # scaled to [0, 1], only for plotting\n",
    "\n",
    "# Plot and show\n",
    "plot3d(img_small_RGB, img_small_rgb)\n",
    "plt.show()\n",
    "\n",
    "plot3d(img_small_HSV, img_small_rgb, axis_labels=list(\"HSV\"))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "colorspace = 'RGB' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 14\n",
    "pix_per_cell = 8\n",
    "cell_per_block = 2\n",
    "hog_channel = \"ALL\" # Can be 0, 1, 2, or \"ALL\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create an array stack of feature vectors\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "print('Using spatial binning of:',spatial,\n",
    "    'and', histbin,'histogram bins')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = 10\n",
    "print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "windows = slide_window(image, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(128, 128), xy_overlap=(0.5, 0.5))\n",
    "                       \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
